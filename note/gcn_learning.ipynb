{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolutional Network (GCN)\n",
    "\n",
    "#### 核心思想\n",
    "\n",
    "- 图卷积层通过**聚合节点的邻居信息**来更新每个节点的特征表示，类似于 CNN 中的卷积操作，但应用于图结构数据\n",
    "\n",
    "#### 主要变量\n",
    "\n",
    "1. 初始化参数\n",
    "\n",
    "- `out_channel`: 每个节点的输出特征维度\n",
    "- `min_deg/max_deg`: 节点度的最小/最大值，用于处理不同连接度的节点\n",
    "- `activation_fn`: 非线性激活函数（如 `ReLU`）\n",
    "\n",
    "2. 输入变量 (`call` 方法)\n",
    "\n",
    "```python\n",
    "inputs = [\n",
    "    atom_features,    # 节点特征矩阵: (n_atoms, n_features)\n",
    "    deg_slice,        # 度信息切片: (n_degrees, 2), 其中 n_degrees 表示可能的度的数目，2 内部为起始的节点索引和这样的节点有多少个\n",
    "    # inputs[2] 在代码中未使用，可能是历史遗留\n",
    "    deg_adj_lists     # 度邻接列表: 每个度对应的邻居索引列表\n",
    "]\n",
    "```\n",
    "\n",
    "3. 核心权重变量\n",
    "\n",
    "```python\n",
    "# build 方法中创建的权重\n",
    "num_deg = 2 * max_deg + (1 - min_deg)               # 权重矩阵数量\n",
    "W_list: [(input_features, out_channel)] * num_deg   # 每个度一个权重矩阵\n",
    "b_list: [(out_channel,)] * num_deg                  # 每个度一个偏置向量\n",
    "```\n",
    "\n",
    "#### 详细计算流程\n",
    "\n",
    "1. 权重初始化 (`build` 方法)\n",
    "\n",
    "```python\n",
    "num_deg = 2 * max_degree + (1 - min_degree)         # 权重数量\n",
    "# 例如：min_deg=0, max_deg=10 → num_deg = 21\n",
    "W_list = [权重矩阵0, 权重矩阵1, ..., 权重矩阵20]\n",
    "b_list = [偏置向量0, 偏置向量1, ..., 偏置向量20]\n",
    "```\n",
    "\n",
    "2. 邻居聚合 (`sum_neigh` 方法)\n",
    "\n",
    "```python\n",
    "def sum_neigh(self, atoms, deg_adj_lists):\n",
    "    # 对每个度的节点，聚合其所有邻居的特征\n",
    "    for deg in range(1, max_degree + 1):    # 初始值为 1, 因为度为 0 的节点没有邻居\n",
    "        # 获取该度所有节点的邻居特征\n",
    "        gathered_atoms = tf.gather(atoms, deg_adj_lists[deg-1])\n",
    "        # 沿邻居维度求和，得到每个节点的邻居聚合特征\n",
    "        summed_atoms = tf.reduce_sum(gathered_atoms, 1)\n",
    "        deg_summed[deg-1] = summed_atoms\n",
    "```\n",
    "\n",
    "变量解释：\n",
    "- `atoms`: 节点特征矩阵，(n_atoms, n_features)\n",
    "- `deg_adj_lists`: 度邻接列表，`deg_adj_lists[deg-1]` 表示所有度为 `deg` 的节点的邻居索引列表\n",
    "- `gathered_atoms`: 度为 `deg` 的所有节点的邻居特征，(n_nodes_with_degree, max_degree, n_features)\n",
    "- `summed_atoms`: 度为 `deg` 的所有节点沿邻居维度求和后的特征结果，(n_nodes_with_degree, n_features)\n",
    "- `deg_summed`: 将度为 `deg` 的所有节点的邻居聚合特征进行存储\n",
    "\n",
    "示例：\n",
    "\n",
    "```python\n",
    "# 图结构：\n",
    "#   0 --- 1\n",
    "#   |     |\n",
    "#   2 --- 3\n",
    "#   |\n",
    "#   4\n",
    "\n",
    "# 节点度：\n",
    "# 节点0: 度2 (连接1,2)\n",
    "# 节点1: 度2 (连接0,3)  \n",
    "# 节点2: 度2 (连接0,3)\n",
    "# 节点3: 度2 (连接1,2)\n",
    "# 节点4: 度1 (连接2)\n",
    "\n",
    "max_degree = 2\n",
    "\n",
    "输入数据\n",
    "\n",
    "# 节点特征\n",
    "atoms = tf.constant([\n",
    "    [1.0, 2.0],  # 节点0特征\n",
    "    [3.0, 4.0],  # 节点1特征\n",
    "    [5.0, 6.0],  # 节点2特征\n",
    "    [7.0, 8.0],  # 节点3特征\n",
    "    [9.0, 1.0]   # 节点4特征\n",
    "])  # shape: (5, 2)\n",
    "\n",
    "# 邻接列表（按度组织）\n",
    "deg_adj_lists = [\n",
    "    [],           # 度0节点（没有）\n",
    "    [[2]],        # 度1：节点4的邻居是[2]\n",
    "    [[1, 2], [0, 3], [0, 3], [1, 2]]  # 度2：节点0,1,2,3的邻居\n",
    "]\n",
    "\n",
    "执行过程\n",
    "\n",
    "# 初始化\n",
    "deg_summed = [None, None]  # max_degree = 2\n",
    "\n",
    "# 循环1: deg = 1\n",
    "deg = 1\n",
    "gathered_atoms = tf.gather(atoms, [[2]])\n",
    "# 结果：[[[5.0, 6.0]]]  # 节点4的邻居特征\n",
    "summed_atoms = tf.reduce_sum(gathered_atoms, 1)\n",
    "# 结果：[[5.0, 6.0]]  # 节点4的邻居聚合特征\n",
    "deg_summed[0] = [[5.0, 6.0]]\n",
    "\n",
    "# 循环2: deg = 2  \n",
    "deg = 2\n",
    "gathered_atoms = tf.gather(atoms, [[1, 2], [0, 3], [0, 3], [1, 2]])\n",
    "# 结果：[\n",
    "#   [[3.0, 4.0], [5.0, 6.0]],  # 节点0的邻居[1,2]的特征\n",
    "#   [[1.0, 2.0], [7.0, 8.0]],  # 节点1的邻居[0,3]的特征\n",
    "#   [[1.0, 2.0], [7.0, 8.0]],  # 节点2的邻居[0,3]的特征\n",
    "#   [[3.0, 4.0], [5.0, 6.0]]   # 节点3的邻居[1,2]的特征\n",
    "# ]\n",
    "\n",
    "summed_atoms = tf.reduce_sum(gathered_atoms, 1)\n",
    "# 结果：[\n",
    "#   [8.0, 10.0],  # [3+5, 4+6] 节点0的邻居聚合\n",
    "#   [8.0, 10.0],  # [1+7, 2+8] 节点1的邻居聚合  \n",
    "#   [8.0, 10.0],  # [1+7, 2+8] 节点2的邻居聚合\n",
    "#   [8.0, 10.0]   # [3+5, 4+6] 节点3的邻居聚合\n",
    "# ]\n",
    "deg_summed[1] = [[8.0, 10.0], [8.0, 10.0], [8.0, 10.0], [8.0, 10.0]]\n",
    "\n",
    "最终结果\n",
    "\n",
    "deg_summed = [\n",
    "    [[5.0, 6.0]],  # 度1节点的邻居聚合\n",
    "    [[8.0, 10.0], [8.0, 10.0], [8.0, 10.0], [8.0, 10.0]]  # 度2节点的邻居聚合\n",
    "]\n",
    "```\n",
    "\n",
    "3. 图卷积计算 (call 方法核心)\n",
    "\n",
    "- 准备阶段\n",
    "\n",
    "```python\n",
    "atom_features = inputs[0]           # (n_atoms, n_features)\n",
    "deg_slice = inputs[1]               # 度信息切片，(n_degrees, 2)\n",
    "deg_adj_lists = inputs[3:]          # 邻接列表\n",
    "W = iter(self.W_list)               # 权重迭代器\n",
    "b = iter(self.b_list)               # 偏置迭代器\n",
    "\n",
    "# 聚合邻居特征\n",
    "deg_summed = self.sum_neigh(atom_features, deg_adj_lists)\n",
    "```\n",
    "\n",
    "- 按度计算节点\n",
    "\n",
    "```python\n",
    "# 按度切分节点特征，内部元素为度相等的节点特征\n",
    "split_features = tf.split(atom_features, deg_slice[:, 1])\n",
    "\n",
    "for deg in range(1, max_degree + 1):\n",
    "    # 获取度为 deg 的节点的邻居聚合特征\n",
    "    rel_atoms = deg_summed[deg - 1]\n",
    "\n",
    "    # 获取度为 deg 的节点自身特征\n",
    "    self_atoms = split_features[deg - min_degree]\n",
    "\n",
    "    # 分别应用线性变换\n",
    "    rel_out = tf.matmul(rel_atoms, next(W)) + next(b)       # 邻居部分\n",
    "    self_out = tf.matmul(self_atoms, next(W)) + next(b)     # 自身部分\n",
    "\n",
    "    # 相加得到该度节点的输出特征\n",
    "    out = rel_out + self_out\n",
    "    new_rel_atoms_collection[deg - min_degree] = out\n",
    "```\n",
    "\n",
    "- 处理孤立节点 (度=0)\n",
    "\n",
    "```python\n",
    "if min_degree == 0:\n",
    "    self_atoms = split_features[0]\n",
    "    # 孤立节点只使用自身特征\n",
    "    out = tf.matmul(self_atoms, next(W)) + next(b)\n",
    "    new_rel_atoms_collection[0] = out\n",
    "```\n",
    "\n",
    "- 合并所有节点\n",
    "\n",
    "```python\n",
    "# 将所有度的节点特征重新拼接\n",
    "atom_features = tf.concat(axis=0, values=new_rel_atoms_collection)\n",
    "\n",
    "# 应用激活函数\n",
    "if activation_fn is not None:\n",
    "    atom_features = activation_fn(atom_features)\n",
    "```\n",
    "\n",
    "#### 数学公式表示\n",
    "\n",
    "对于度为 d 的节点 i：\n",
    "\n",
    "$$h_i^{(l+1)} = \\sigma(W_{self}^{(d)} \\cdot h_i^{(l)} + W_{neigh}^{(d)} \\cdot \\sum_{j \\in N(i)} h_j^{(l)} + b^{(d)})$$\n",
    "\n",
    "其中：\n",
    "- $h_i^{(l)}$ 是节点 i 在第 l 层的特征\n",
    "- $N(i)$ 是节点 i 的邻居集合\n",
    "- $W_{self}^{(d)}$ 和 $W_{neigh}^{(d)}$ 是度为 d 的节点的权重矩阵\n",
    "- $\\sigma$ 是激活函数\n",
    "\n",
    "#### 数值示例\n",
    "\n",
    "假设有一个简单图：\n",
    "- 节点0（度1）：特征 [1, 2]\n",
    "- 节点1（度2）：特征 [3, 4]\n",
    "- 节点2（度1）：特征 [5, 6]\n",
    "- 连接：0-1-2\n",
    "\n",
    "```python\n",
    "# 输入数据\n",
    "atom_features = [[1, 2], [3, 4], [5, 6]]                # (3, 2)\n",
    "deg_slice = [[0, 2], [1, 1]]                            # 度0有2个节点，度1有1个节点\n",
    "deg_adj_lists = [[2], [0, 2]]                           # 度1节点0的邻居是节点2，度2节点1的邻居是0,2\n",
    "\n",
    "# 权重初始化（假设out_channel=3）\n",
    "W_list = [W_self_0, W_neigh_0, W_self_1, W_neigh_1, W_self_2, W_neigh_2]\n",
    "b_list = [b_self_0, b_neigh_0, b_self_1, b_neigh_1, b_self_2, b_neigh_2]\n",
    "\n",
    "# 计算邻居聚合\n",
    "deg_summed[0] = [atom_features[2]]                      # 节点0的邻居是节点2\n",
    "deg_summed[1] = [atom_features[0] + atom_features[2]]   # 节点1的邻居是0和2\n",
    "\n",
    "# 分别计算各度节点的输出\n",
    "# 度1节点（节点0,2）：\n",
    "rel_out_deg1 = deg_summed[0] @ W_neigh_1 + b_neigh_1\n",
    "self_out_deg1 = atom_features[[0,2]] @ W_self_1 + b_self_1\n",
    "output_deg1 = rel_out_deg1 + self_out_deg1\n",
    "\n",
    "# 度2节点（节点1）：\n",
    "rel_out_deg2 = deg_summed[1] @ W_neigh_2 + b_neigh_2\n",
    "self_out_deg2 = atom_features[[1]] @ W_self_2 + b_self_2\n",
    "output_deg2 = rel_out_deg2 + self_out_deg2\n",
    "\n",
    "# 最终输出合并\n",
    "final_output = concat([output_deg1, output_deg2])       # 按原始节点顺序\n",
    "```\n",
    "\n",
    "#### 关键设计特点\n",
    "\n",
    "1. **度特化**: 不同度的节点使用不同的权重矩阵，捕获不同连接模式\n",
    "2. **邻居聚合**: 对邻居特征求和，捕获局部图结构信息\n",
    "3. **自身+邻居**: 同时考虑节点自身特征和邻居信息\n",
    "4. **批量处理**: 可以并行处理多个图的节点\n",
    "\n",
    "这种设计特别适合分子图等具有不规则度分布的图结构数据\n",
    "\n",
    "---\n",
    "\n",
    "### LSTMStep\n",
    "\n",
    "#### 核心概念回顾\n",
    "\n",
    "- `LSTM` 通过三个门控机制（输入门、遗忘门、输出门）来控制信息的流动，解决传统 RNN 的梯度消失问题\n",
    "\n",
    "#### 变量详细解释\n",
    "\n",
    "1. 输入变量\n",
    "\n",
    "- `x`: 当前时间步的输入向量，形状 (batch_size, input_dim)\n",
    "- `h_tm1`: 前一时间步的隐藏状态，形状 (batch_size, output_dim)，其中 `output_dim` 包含了四个门的输出维度\n",
    "- `c_tm1`: 前一时间步的记忆状态（细胞状态），形状 (batch_size, output_dim)\n",
    "\n",
    "2. 权重矩阵\n",
    "\n",
    "- `W`: 输入到隐藏的权重矩阵，形状 (input_dim, 4*output_dim)\n",
    "    - 控制输入 x 对所有门的影响\n",
    "- `U`: 隐藏到隐藏的权重矩阵，形状 (output_dim, 4*output_dim)\n",
    "    - 控制前一隐藏状态对所有门的影响\n",
    "\n",
    "3. 偏置变量\n",
    "\n",
    "- `b`: 偏置向量，长度 4*output_dim\n",
    "    - 包含 4 个门的偏置：[b_input, b_forget, b_candidate, b_output]\n",
    "    - 初始化：[0, 1, 0, 0]（遗忘门偏置为1，倾向于保留信息）\n",
    "\n",
    "#### 详细计算过程\n",
    "\n",
    "1. 线性组合计算\n",
    "\n",
    "```python\n",
    "z = backend.dot(x, self.W) + backend.dot(h_tm1, self.U) + self.b\n",
    "```\n",
    "\n",
    "- `z` 形状：(batch_size, 4*output_dim)\n",
    "- 这是所有门的原始激活值，尚未经过激活函数\n",
    "\n",
    "2. 门控值分割\n",
    "\n",
    "```python\n",
    "z0 = z[:, :self.output_dim]                     # 输入门原始值\n",
    "z1 = z[:, self.output_dim:2*self.output_dim]    # 遗忘门原始值  \n",
    "z2 = z[:, 2*self.output_dim:3*self.output_dim]  # 候选记忆原始值\n",
    "z3 = z[:, 3*self.output_dim:]                   # 输出门原始值\n",
    "```\n",
    "\n",
    "3. 门控激活\n",
    "\n",
    "```python\n",
    "i = self.inner_activation_fn(z0)                # 输入门: sigmoid(0,1)\n",
    "f = self.inner_activation_fn(z1)                # 遗忘门: sigmoid(0,1) \n",
    "c = f * c_tm1 + i * self.activation_fn(z2)      # 新记忆状态\n",
    "o = self.inner_activation_fn(z3)                # 输出门: sigmoid(0,1)\n",
    "```\n",
    "\n",
    "4. 最终输出\n",
    "\n",
    "```python\n",
    "h = o * self.activation_fn(c)                   # 新隐藏状态\n",
    "return h, [h, c]                                # 返回隐藏状态和完整状态\n",
    "```\n",
    "\n",
    "#### 数学公式详细解析\n",
    "\n",
    "1. 输入门 (Input Gate)\n",
    "\n",
    "$$i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i)$$\n",
    "\n",
    "- 控制多少新信息写入记忆状态\n",
    "- `i_t` 接近1：大量写入新信息\n",
    "- `i_t` 接近0：少量写入新信息\n",
    "\n",
    "2. 遗忘门 (Forget Gate)\n",
    "\n",
    "$$f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f)$$\n",
    "\n",
    "- 控制保留多少历史信息\n",
    "- f_t 接近1：保留更多历史信息\n",
    "- f_t 接近0：遗忘更多历史信息\n",
    "\n",
    "3. 候选记忆 (Candidate Memory)\n",
    "\n",
    "$$\\tilde{C}t = \\tanh(W_c x_t + U_c h{t-1} + b_c)$$\n",
    "\n",
    "- 当前时间步的新信息候选\n",
    "- 通过 tanh 压缩到 [-1, 1] 范围\n",
    "\n",
    "4. 记忆状态更新\n",
    "\n",
    "$$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$$\n",
    "\n",
    "- 新记忆状态 = 遗忘的历史 + 新输入的信息\n",
    "- ⊙ 表示逐元素乘法\n",
    "\n",
    "5. 输出门 (Output Gate)\n",
    "\n",
    "$$o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o)$$\n",
    "\n",
    "- 控制从记忆状态中输出多少信息\n",
    "\n",
    "6. 隐藏状态输出\n",
    "\n",
    "$$h_t = o_t \\odot \\tanh(C_t)$$\n",
    "\n",
    "- 最终的隐藏状态输出\n",
    "\n",
    "#### 完整的数值示例\n",
    "\n",
    "假设参数：\n",
    "\n",
    "- `batch_size` = 2, `input_dim` = 3, `output_dim` = 4\n",
    "\n",
    "```python\n",
    "# 输入\n",
    "x = [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]      # (2,3)\n",
    "h_tm1 = [[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8]]  # (2,4)  \n",
    "c_tm1 = [[0.2, 0.3, 0.4, 0.5], [0.6, 0.7, 0.8, 0.9]]  # (2,4)\n",
    "\n",
    "# 权重矩阵 (随机初始化)\n",
    "W = [[...], ...]  # (3, 16)\n",
    "U = [[...], ...]  # (4, 16)  \n",
    "b = [0,0,0,0, 1,1,1,1, 0,0,0,0, 0,0,0,0]  # (16,)\n",
    "\n",
    "# 计算过程\n",
    "z = x @ W + h_tm1 @ U + b  # (2,16)\n",
    "z0 = z[:, :4]    # 输入门部分 (2,4)\n",
    "z1 = z[:, 4:8]   # 遗忘门部分 (2,4)\n",
    "z2 = z[:, 8:12]  # 候选记忆部分 (2,4)  \n",
    "z3 = z[:, 12:16] # 输出门部分 (2,4)\n",
    "\n",
    "i = sigmoid(z0)  # 输入门激活值 (2,4)\n",
    "f = sigmoid(z1)  # 遗忘门激活值 (2,4)\n",
    "c_candidate = tanh(z2)  # 候选记忆 (2,4)\n",
    "o = sigmoid(z3)  # 输出门激活值 (2,4)\n",
    "\n",
    "# 状态更新\n",
    "c = f * c_tm1 + i * c_candidate  # 新记忆状态 (2,4)\n",
    "h = o * tanh(c)  # 新隐藏状态 (2,4)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
